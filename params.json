{"name":"Dataone","tagline":"DAP-DataONE Server Documentation","body":"# Welcome to the DAP-DataONE server documentation\r\nThe DAP-DataONE server is an implementation of a DataONE version 1, tier 1 Member Node. It is designed to act as a kind of broker for DataONE clients and data served using OPeNDAP. The initial version of the server only supports DAP2 but will work with any DAP server that can return data packaged in netCDF3 files and can return ISO-19115 metadata documents for those datasets. The server is implemented as a Java Servlet that contains the implementation of the DataONE Member Node protocol and a simple database paired with a command-line to add or update datasets in the database. The database uses SQLite, although all of the software interacts with it using JDBC, so a different RDB could be used with only very trivial modifications to the software.\r\n\r\n## What's here in the documentation?\r\nThe documentation contains information about how to:\r\n1. Beta software\r\n1. Build the software from source\r\n1. Test the software using a preconfigured database\r\n1. Serving your own data\r\n\r\nIn addition, there is documentation that discusses ways the server could be made more powerful and limitations imposed by the designs of DAP2 and DataONE:\r\n1. How it works\r\n1. Optimizations\r\n1. Limitations\r\n\r\n## Beta software; What we assume\r\nThis is beta software without a polished build/install process. We assume you are computer savvy and know how to configure systems, install software, start and stop web servers, ..., all that stuff. If you want to use this software but are unsure about these kinds of things, contact us at support@opendap.org or [DataONE:Contact](https://www.dataone.org/contact).\r\n\r\n## Build the software\r\nThis project and its companion, DAPD1DatasetsDatabase, use Maven. \r\n\r\n### Get Maven if you do not already have it\r\nGoto http://maven.apache.org/download.cgi, get the binary and install it. On a Mac OSX machine, put the `apache-maven-<ver>` directory in `/Applications`. Then add\r\n* export M2_HOME=/Applications/apache-maven-3.1.1\r\n* export PATH=$PATH:$M2_HOME/bin\r\nto `.bashrc` or the equivalent. `mvn --version` should work and return the expected info.\r\n\r\n### Build the code\r\nUse git to `clone` the [DAPD1DatasetsDatabase](https://github.com/jgallagher59701/DAPD1DatasetsDatabase) and [DAPD1Servlet](ttps://github.com/jgallagher59701/DAPD1Servlet) projects (hosted here on GitHub). It's best to store them in the same directory even though they are completely separate projects. For the DAPD1DatasetsDatabase, build it using `mvn clean install`. This will build the executable jar file run by the edit-db.sh bash shell script and install that in the local maven repository so it can be found by the DAPD1Servlet build. To build the DAPD1Servlet code, use `mvn clean package`. This will build a `war` file that can be installed in tomcat's `webapps` subdirectory. If there's a significant demand, we can make binaries available.\r\n\r\nNote:\r\n> I use Eclipse with the Maven plugin ([m2e](http://download.eclipse.org/technology/m2e/releases)). Once the code is checked out > using `git clone`, then use Eclipse:File:Import... and choose Git->Existing local repository and select the 'import as general > project' option. In the project, Right click on the `pox.xml` file and choose Run As... to build.\r\n\r\n### Configure and Test the Server\r\nTo install the server, you'll need an instance of Tomcat. Copy the `target/DAPD1Servlet.war` to Tomcat's `webapps` directory. Start Tomcat and then ten stop it. This little gyration will make a default 'opendap.properties' file that you can then edit. Look in `$CATALINA_HOME/webapps/DAPD1Servlet/WEB-INF/classes/` for that file and edit it as follows:\r\n* `org.opendap.d1.serviceName = http://<host>:<port>/DAPD1Servlet/d1` where `<host>` and `<port>` match where you are running Tomcat.\r\n* org.opendap.d1.DatabaseName = `<path to the database>`. In the DAPD1DatasetsDatabase project there is a test database named `test.db` that you can use for testing. Once you know the server's working, you'll need to build your own database and change this parameter value to reference it.\r\n* org.opendap.d1.nodeName = `<DAP server host name>`, e.g., `test.opendap.org`. This is the DAP server that will be tested by the `ping` function. Note that the DAPD1DatasetsDatabase doesn't enforce that this is the only DAP server used, but it should be that case that the database holds only DAP datasets served by this host. For now, we're using the honor system ;-)\r\n* org.opendap.d1.nodeId = `<URN for the node>`, e.g., urn:node:test_opendap_org. This cannot use dots.\r\n* org.opendap.d1.subject = `public` Currently only 'public' access is supported\r\n* org.opendap.d1.contactSubject = `<contact information`, e.g., `CN=James Gallagher,O=OPeNDAP,C=US`\r\n* org.opendap.d1.nodeDescription = `<Text description>`, e.g., `This node contains test data.`\r\nOnce you have edited this file, make a copy of it someplace safe since the file will be overwritten if the `war` file is updated and you'd loose all your configuration information.\r\n\r\nStart tomcat. If the `test.db` database is correctly referenced by the `org.opendap.d1.DatabaseName` option, the servlet should start without errors. Look in Tomcat's `catalina.out` log file to verify that is has started without error. If there are errors, edit the `logback.xml` file in the ... and set the log level to `DEBUG` in the logger named \"org.opendap.d1\". Also note that the servlet writes log messages to a log file named 'opendap.log'.\r\n\r\nAssuming Tomcat and the Servlet start without errors, try these URLs (I'll use `localhost:8080` for the host and port):\r\n* Test the `ping` function: http://localhost:8080/DAPD1Servlet/d1/mn/v1/monitor/ping. This should return the time of the ping, but it may take a few seconds since it will test to see that your DAP server is really responding.\r\n* Look at the objects: http://localhost:8080/DAPD1Servlet/d1/mn/v1/object.\r\n* Look at the information for a given PID: http://localhost:8080/DAPD1Servlet/d1/mn/v1/object/...\r\n* Look at that PID's metadata: http://localhost:8080/DAPD1Servlet/d1/mn/v1/meta/...\r\n\r\n### Serving your own data\r\nSee the information about adding and updating datasets in the database over in the [DAPD1DatasetsDatabase project](https://github.io/jgallagher59701/DAPD1DatasetsDatabase). Once this database has been built, copy it to a safe place and edit the `org.opendap.d1.DatabaseName` parameter so that it references it. Restart the servlet, check for errors and test.\r\n\r\n## About the design, potential optimizations and its current limitations\r\nThis is the first attempt at a broker (using the term loosely) for DAP and DataONE and was written quickly. The DataONE Java libraries along with an example servlet made the process go quite fast (about 5 weeks total development time). However, there are significant differences in some of the goals of the DAP and DataONE technologies and those differences are the subject of this section. Fundamentally, DAP is a **protocol** for data access and subsetting while DataONE is a **system** that provides a complete solution to a range of activities important to users of online data. This difference means that DataONE provides one or more solutions to a range of problems (data persistance, location, etc.) in addition to data access. In many ways that is what makes combining the two so interesting. With that in mind...\r\n\r\n### How it works\r\nThe server uses two characteristics of many DAP implementations to provide two of the three most important responses of the DataONE Tier 1 Member Node: The Science Data Object (SDO) and Science Metadata Object (SMO). DAP servers often provide a way to access data packages in a netCDF3 (or 4) file - regardless of how the data are originally stored. Thus the DAP-DataONE server is designed to always return the SDO as a netCDF3 file. The original data might have been stored in a RDB, or a HDF4 File, but the return format from the DAP-DataONE server will always be as a netCDF3 file. The SMO - a metadata object that matches the SDO - is built using many DAP server's ability to build ISO-19115 documents that describe any given dataset. Lastly, the ORE document, the third primary DataONE response, is built using the URLs for the SDO and SMO. \r\n\r\nThe DAP URL to the dataset is used to build the URLs that are used to access the SDO and SMO from the DAP server. For each dataset that the DAP server holds, there is one base URL and from the base URL there is one URL that will return a netCDF3 file that holds all of it s data (the SDO) and one URL that will return the ISO-19115 document (the SMO).\r\n\r\nHowever, DataONE requires other information about any given dataset. For each of the SDO, SMO and ORE responses, DataONE specifies a set of 'system metadata' that must also be made available by a DataONE server. This information includes a Persistent Identifier (PID) that is used to access the response, the size and checksum of the response as well as other metadata. The DAP-DataONE server uses a relational database to store this information.\r\n\r\nThe DAP-DataONE server uses SQLite (although it will be trivial to substitute a different database engine like MySQL) to store the metadata, PIDs, and other information including the ORE documents. This information is accessed and used to build every response **except** the SDO and SMO responses. The SDO and SMO responses are read from the DAP server, not the relational database. The [DAPD1DatasetsDatabase](https://github.com/jgallagher59701/DAPD1DatasetsDatabase) project web page contains information about the tables in the current implementation of the datasets database. \r\n\r\nThe DataONE server also uses the RDB to store access information. Information about every SDO or SMO request is stored in a table and can be queried using the DataONE 'log' function.\r\n\r\n## Optimizations\r\nFrom the preceding description, it should be clear that one optimization for the server would be to cache the ISO-19115 metadata document, either in the database or using a separate cache tool like the Java Caching System (JCS). This would speed up the response for these objects. Similarly, if sufficient memory is available for a server, caching the SDO would also boost performance, although this would likely be a real cache in the sense that old items would be pushed out to make room for newer or more frequently requested things. The current 'caching' of the ORE documents stores all of them permanently.\r\n\r\nThere are some quirks to the server's design that could be addressed, and while not really optimizations, doing these things would improve performance. First, the servlet and the database are loosely coupled, normally that's a good thing but in this case it can lead to some odd behavior. In particular, the server has a single server set at the 'DAP server' with the implication that all data are served from that one site. However, there's no limitation on the number of different sites can be in the database. In fact, the database has no notion of sites at all; it simply holds URLs without considering where they will read data from. The 'ping' function will use the 'DAP server' named in the configuration parameter, however. SO if ping returns, the client knows that the DAP server named by that parameter is working. \r\n\r\n## Limitations\r\n\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}